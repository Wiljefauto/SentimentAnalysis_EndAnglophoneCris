library(rtweet)
library(httpuv)
library(tidytext)
library(tidyverse)
library(ggplot2)
api_key <- "080X2ef1ZQ97dVFkLuoqodnZW"
api_secret_key <- "OZgfcXDAj6lCnSx7CwHykm7ISZdu0T4pjkEeOAkYwBaxzEAzuR"
token <- create_token(
app = "MSI_UCAC_App",
consumer_key = api_key,
consumer_secret = api_secret_key)
api_key <- "84hTf7ic2FzsB8sewk7BMBFqT"
api_secret_key <- "xZ1KEouC8afOPjsGwKG2SeJTRwnzDmD2Erm5w2JbVhd3YTnvVs"
token <- create_token(
app = "MSI_UCAC_App",
consumer_key = api_key,
consumer_secret = api_secret_key)
nosocrisis_tweets <- search_tweets(q = "#endanglophonecrisis", n = 3000, lang ="en", include_rts = FALSE)
class(nosocrisis_tweets)
View(nosocrisis_tweets)
#Exporting tweets pulled in a .csv file
write_as_csv(nosocrisis_tweets, "nosocrisis_tweets.csv")
head(nosocrisis_tweets$text)
nosocrisis_tweets$text <-  gsub("https\\S*", "", nosocrisis_tweets$text)
nosocrisis_tweets$text <-  gsub("@\\S*", "", nosocrisis_tweets$text)
nosocrisis_tweets$text  <-  gsub("amp", "", nosocrisis_tweets$text)
nosocrisis_tweets$text  <-  gsub("[\r\n]", "", nosocrisis_tweets$text)
nosocrisis_tweets$text  <-  gsub("[[:punct:]]", "", nosocrisis_tweets$text)
tweets <- nosocrisis_tweets %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(stop_words)
head(nosocrisis_tweets$text)
library(wordcloud)
tweets %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors = "#F29545"))
View(tweets)
View(nosocrisis_tweets)
tweets %>%
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets containing #EndAnglophoneCrisis",
subtitle = "Stop words removed from the list")
set.seed(1234)
wordcloud(tweets$text, min.freq=5, scale=c(3.5, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library(tm)
library(wordcloud)
set.seed(1234)
wordcloud(tweets$text, min.freq=5, scale=c(3.5, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
nosocrisis_tweets$text <- as.character(nosocrisis_tweets$text)
nosocrisis_tweets$text <- gsub("c\\(", "", nosocrisis_tweets$text)
set.seed(1234)
wordcloud(tweets$text, min.freq=5, scale=c(3.5, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$text, min.freq=5, scale=c(3.5, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$text, min.freq=15, scale=c(3.5, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
head(nosocrisis_tweets$text)
nosocrisis_tweets$text <-  gsub("https\\S*", "", nosocrisis_tweets$text)
nosocrisis_tweets$text <-  gsub("@\\S*", "", nosocrisis_tweets$text)
nosocrisis_tweets$text  <-  gsub("amp", "", nosocrisis_tweets$text)
nosocrisis_tweets$text  <-  gsub("[\r\n]", "", nosocrisis_tweets$text)
nosocrisis_tweets$text  <-  gsub("[[:punct:]]", "", nosocrisis_tweets$text)
tweets <- nosocrisis_tweets %>%
select(text) %>%
unnest_tokens(word, text)
tweets <- tweets %>%
anti_join(stop_words)
tweets %>%
count(word, sort = TRUE) %>%
top_n(15) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
labs(y = "Count",
x = "Unique words",
title = "Most frequent words found in the tweets containing #EndAnglophoneCrisis",
subtitle = "Stop words removed from the list")
words <- tweets %>%
mutate(text = str_remove_all(text, "&amp;|&lt;|&gt;"),
text = str_remove_all(text, "\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)"),
text = str_remove_all(text, "[^\x01-\x7F]")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!str_detect(word, "^#"),
!str_detect(word, "@\\S+")) %>%
count(word, sort = TRUE)
words <- nosocrisis_tweets %>%
mutate(text = str_remove_all(text, "&amp;|&lt;|&gt;"),
text = str_remove_all(text, "\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)"),
text = str_remove_all(text, "[^\x01-\x7F]")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!str_detect(word, "^#"),
!str_detect(word, "@\\S+")) %>%
count(word, sort = TRUE)
View(words)
library(wordcloud)
words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors = "#F29545"))
library(wordcloud)
words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, scale=c(3.5, .5), rot.per=0.35, colors=brewer.pal(8, "Dark2")))
words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=brewer.pal(8, "Dark2")))
View(words)
View(words)
words %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 100, colors=brewer.pal(8, "Dark2")))
wordcloud(words = d$word, freq = d$freq, min.freq = 5, max.words=200, random.order=FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(words %% = d$word, freq = d$freq, min.freq = 5, max.words=200, random.order=FALSE, colors=brewer.pal(8, "Dark2"))
words %%
with(wordcloud(word, freq = d$freq, min.freq = 5, max.words=200, random.order=FALSE, colors=brewer.pal(8, "Dark2")))
words %%
with(wordcloud(words = words$word, freq = words$freq, min.freq = 5, max.words=200, random.order=FALSE, colors=brewer.pal(8, "Dark2")))
words %%
with(wordcloud(words = words$word, freq = words$freq, min.freq = 5, max.words=100, random.order=FALSE, colors=brewer.pal(8, "Dark2")))
words %%
with(wordcloud(words = words$word, freq = words$freq, min.freq = 5, random.order=FALSE, colors=brewer.pal(8, "Dark2")))
View(nosocrisis_tweets)
# Wordcloud of frequent used words
head(nosocrisis_tweets$hashtags)
nosocrisis_tweets$hashtags <- as.character(nosocrisis_tweets$hashtags)
nosocrisis_tweets$hashtags <- gsub("c\\(", "", nosocrisis_tweets$hashtags)
set.seed(1234)
wordcloud(nosocrisis_tweets$hashtags, min.freq=5, scale=c(3.5, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(3.5, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(2.5, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(1.5, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(1.2, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(1.2, .5), random.order=FALSE, rot.per=0.25,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(1.2, .5), random.order=FALSE, rot.per=0.55,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(1.2, .5), random.order=FALSE, rot.per=0.95,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(1.2, .5), random.order=FALSE, rot.per=2.5,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(1.2, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
set.seed(1234)
wordcloud(nosocrisis_tweets$retweet_screen_name, min.freq=10, scale=c(2, .5), random.order=FALSE, rot.per=0.25,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$retweet_screen_name, min.freq=3, scale=c(2, .5), random.order=FALSE, rot.per=0.25,
colors=brewer.pal(8, "Dark2"))
# Twitter accounts from which most tweets originated
head(nosocrisis_tweets$screen_name)
wordcloud(nosocrisis_tweets$hashtags, min.freq=10, scale=c(1.2, .5), random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(nosocrisis_tweets$retweet_screen_name, min.freq=3, scale=c(2, .5), random.order=FALSE, rot.per=0.25,
colors=brewer.pal(8, "Dark2"))
# Twitter accounts from which most tweets originated
head(nosocrisis_tweets$source)
library(syuzhet)
# Converting tweets to ASCII to trackle strange characters
tweets <- iconv(tweets, from="UTF-8", to="ASCII", sub="")
# removing retweets, in case needed
tweets <-gsub("(RT|via)((?:\\b\\w*@\\w+)+)","",tweets)
# removing mentions, in case needed
tweets <-gsub("@\\w+","",tweets)
ew_sentiment<-get_nrc_sentiment((tweets))
sentimentscores<-data.frame(colSums(ew_sentiment[,]))
names(sentimentscores) <- "Score"
sentimentscores <- cbind("sentiment"=rownames(sentimentscores),sentimentscores)
rownames(sentimentscores) <- NULL
ggplot(data=sentimentscores,aes(x=sentiment,y=Score))+
geom_bar(aes(fill=sentiment),stat = "identity")+
theme(legend.position="none")+
xlab("Sentiments")+ylab("Scores")+
ggtitle("Total sentiment based on scores")+
theme_minimal()
View(sentimentscores)
nosocrisis_app <- nosocrisis_tweets %>%
select(source) %>%
group_by(source) %>%
summarize(count=n())
nosocrisis_app <- subset(nosocrisis_app, count > 15)
View(nosocrisis_app)
nosocrisis_app <- subset(nosocrisis_app, count > 05)
View(nosocrisis_app)
nosocrisis_app <- nosocrisis_tweets %>%
select(source) %>%
group_by(source) %>%
summarize(count=n())
nosocrisis_app <- subset(nosocrisis_app, count > 05)
nosocrisis_app <- nosocrisis_tweets %>%
select(source) %>%
group_by(source) %>%
summarize(count=n())
View(nosocrisis_app)
nosocrisis_app <- subset(nosocrisis_app, count > 15)
data <- data.frame(
category=nosocris_app$source,
count=nosocris_app$count
)
data <- data.frame(
category=nosocrisis_app$source,
count=nosocris_app$count
)
data <- data.frame(
category=nosocrisis_app$source,
count=nosocrisis_app$count
)
data$fraction = data$count / sum(data$count)
data$percentage = data$count / sum(data$count) * 100
data$ymax = cumsum(data$fraction)
data$ymin = c(0, head(data$ymax, n=-1))
data <- round_df(data, 2)
Source <- paste(data$category, data$percentage, "%")
#Plotting a donut chart to illustrate the result
install.packages("socviz")
library(socviz)
data <- data.frame(
category=nosocrisis_app$source,
count=nosocrisis_app$count
)
data$fraction = data$count / sum(data$count)
data$percentage = data$count / sum(data$count) * 100
data$ymax = cumsum(data$fraction)
data$ymin = c(0, head(data$ymax, n=-1))
data <- round_df(data, 2)
Source <- paste(data$category, data$percentage, "%")
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Source)) +
geom_rect() +
coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
xlim(c(2, 4)) +
theme_void() +
theme(legend.position = "right")
ts_plot(nosocrisis_tweets, "years") +
labs(x = NULL, y = NULL,
title = "Frequency of tweets with a #EndAnglophoneCrisis hashtag",
subtitle = paste0(format(min(nosocrisis_tweets$created_at), "%d %B %Y"), " to ", format(max(nosocrisis_tweets$created_at),"%d %B %Y")),
caption = "Data collected from Twitter's REST API via rtweet") +
theme_minimal()
ts_plot(nosocrisis_tweets, "hours") +
labs(x = NULL, y = NULL,
title = "Frequency of tweets with a #EndAnglophoneCrisis hashtag",
subtitle = paste0(format(min(nosocrisis_tweets$created_at), "%d %B %Y"), " to ", format(max(nosocrisis_tweets$created_at),"%d %B %Y")),
caption = "Data collected from Twitter's REST API via rtweet") +
theme_minimal()
nosocrisis_tweets %>%
filter(!is.na(place_full_name)) %>%
count(place_full_name, sort = TRUE) %>%
top_n(5)
nosocrisis_tweets %>%
count(screen_name, sort = TRUE) %>%
top_n(10) %>%
mutate(screen_name = paste0("@", screen_name))
View(nosocrisis_tweets)
View(nosocrisis_app)
View(nosocrisis_tweets)
users %>%
count(location, sort = TRUE) %>%
mutate(location = reorder(location, n)) %>%
top_n(20) %>%
na.omit() %>%
ggplot(aes(x = location, y = n)) +
geom_col() +
coord_flip() +
labs(x = "Count",
y = "Location",
title = "Locations of people tweeting about #EndAnglophoneCrisis")
users <- search_users("#endanglophonecrisis", lang ="en",
n = 500)
nosocrisis_tweets %>%
filter(!is.na(place_full_name)) %>%
count(place_full_name, sort = TRUE) %>%
top_n(5)
nosocrisis_tweets %>%
count(screen_name, sort = TRUE) %>%
top_n(10) %>%
mutate(screen_name = paste0("@", screen_name))
View(nosocrisis_app)
View(sentimentscores)
